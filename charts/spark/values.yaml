# Default values for spark.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

image:
  repository: ""
  pullPolicy: IfNotPresent
  # Overrides the image tag whose default is the chart appVersion.
  tag: ""

imagePullSecrets: []
nameOverride: ""
fullnameOverride: ""

serviceAccount:
  # Specifies whether a service account should be created
  create: true
  # Annotations to add to the service account
  annotations: {}
  # The name of the service account to use.
  # If not set and create is true, a name is generated using the fullname template
  name: "spark"

rbac:
  create: false

sparkApplication:
  type: Scala
  mode: cluster
  mainClass: ""
  arguments: []
  mainApplicationFile: ""
  version: "3.1.1"
  conf:
    eventLogEnabled: true
    eventLogDir: ""
    # true if dynamicAllocation is set to true that will help fault resilience
    dynamicAllocationShuffleTrackingEnabled: true
  pvcs: {}
  restartPolicy:
    type: Never
  volumes: []
  driver:
    javaOptions: ""
    cores: 1
    coreLimit: ""
    memory: ""
    memoryOverhead: ""
    volumeMounts: []
  executor:
    javaOptions: ""
    cores: 1
    coreLimit: ""
    memory: ""
    memoryOverhead: ""
    volumeMounts: []
  envs: []
  envSecretKeyRefs: {}
  monitoring:
    exposeDriverMetrics: true
    exposeExecutorMetrics: true
    prometheus:
      jmxExporterJar: ""
      port: 8090
  dynamicAllocation:
    enabled: true
    initialExecutors: 1
    minExecutors: 1
    maxExecutors: 10

tolerations: []

affinity: {}

# testing purpose
service:
  type: ClusterIP
  port: 80